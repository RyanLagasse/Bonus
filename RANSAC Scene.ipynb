{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def extract_frames_from_video(video_path: str, output_dir: str, frame_interval: int = 60) -> None:\n",
    "    \"\"\"\n",
    "    Extracts frames from a video file at a specified interval and saves them to a directory.\n",
    "\n",
    "    Args:\n",
    "        video_path (str): Path to the input video file.\n",
    "        output_dir (str): Path to the output directory for saving the extracted frames.\n",
    "        frame_interval (int): Interval (in frames) at which frames are extracted. Default is 60 frames.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Open the video file\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Get the total number of frames in the video\n",
    "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Initialize the frame counter\n",
    "    frame_count = 0\n",
    "\n",
    "    # Loop through the frames and save every frame_interval-th frame\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_count % frame_interval == 0:\n",
    "            frame_path = os.path.join(output_dir, f\"frame_{frame_count}.jpg\")\n",
    "            cv2.imwrite(frame_path, frame)\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    # Release the video capture object\n",
    "    video.release()\n",
    "\n",
    "def convert_to_grayscale(images: List[np.ndarray]) -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Converts a list of RGB images to grayscale.\n",
    "\n",
    "    Args:\n",
    "        images (List[np.ndarray]): List of RGB images.\n",
    "\n",
    "    Returns:\n",
    "        List[np.ndarray]: List of grayscale images.\n",
    "    \"\"\"\n",
    "    gray_images = []\n",
    "    for image in images:\n",
    "        gray_image = np.dot(image[..., :3], [0.299, 0.587, 0.114])\n",
    "        gray_images.append(gray_image)\n",
    "    return gray_images\n",
    "\n",
    "def enhance_images(gray_images: List[np.ndarray]) -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Enhances a list of grayscale images using contrast stretching.\n",
    "\n",
    "    Args:\n",
    "        gray_images (List[np.ndarray]): List of grayscale images.\n",
    "\n",
    "    Returns:\n",
    "        List[np.ndarray]: List of enhanced grayscale images.\n",
    "    \"\"\"\n",
    "    enhanced_images = []\n",
    "    for image in gray_images:\n",
    "        min_val = np.min(image)\n",
    "        max_val = np.max(image)\n",
    "        enhanced_image = (image - min_val) / (max_val - min_val) * 255\n",
    "        enhanced_image = np.clip(enhanced_image, 0, 255).astype(np.uint8)\n",
    "        enhanced_images.append(enhanced_image)\n",
    "    return enhanced_images\n",
    "\n",
    "def detect_features(images: List[np.ndarray]) -> List[List[Tuple[int, int]]]:\n",
    "    \"\"\"\n",
    "    Detects features in a list of grayscale images using the Harris corner detector.\n",
    "\n",
    "    Args:\n",
    "        images (List[np.ndarray]): List of grayscale images.\n",
    "\n",
    "    Returns:\n",
    "        List[List[Tuple[int, int]]]: List of lists of keypoints, where each inner list corresponds to the keypoints detected in the corresponding image.\n",
    "    \"\"\"\n",
    "    feature_list = []\n",
    "    for image in images:\n",
    "        keypoints = harris_corner_detector(image)\n",
    "        feature_list.append(keypoints)\n",
    "    return feature_list\n",
    "\n",
    "def harris_corner_detector(image: np.ndarray, k: float = 0.04) -> List[Tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    Implements the Harris corner detector algorithm.\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): Grayscale image.\n",
    "        k (float): Sensitivity factor. Default is 0.04.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[int, int]]: List of keypoints (x, y) coordinates.\n",
    "    \"\"\"\n",
    "    # Compute image derivatives\n",
    "    sobelx = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobely = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "\n",
    "    # Compute Harris response matrix\n",
    "    Ixx = sobelx ** 2\n",
    "    Ixy = sobelx * sobely\n",
    "    Iyy = sobely ** 2\n",
    "\n",
    "    # Compute Harris corner response\n",
    "    harris_response = (Ixx * Iyy - Ixy ** 2) - k * ((Ixx + Iyy) ** 2)\n",
    "\n",
    "    # Find keypoints\n",
    "    keypoints = []\n",
    "    for y in range(harris_response.shape[0]):\n",
    "        for x in range(harris_response.shape[1]):\n",
    "            if harris_response[y, x] > 0.01 * harris_response.max():\n",
    "                keypoints.append((x, y))\n",
    "\n",
    "    return keypoints\n",
    "\n",
    "def match_features_across_pairs(feature_list: List[List[Tuple[int, int]]]) -> List[List[Tuple[Tuple[int, int], Tuple[int, int]]]]:\n",
    "    \"\"\"\n",
    "    Matches features across pairs of images using a simple brute-force matching approach.\n",
    "\n",
    "    Args:\n",
    "        feature_list (List[List[Tuple[int, int]]]): List of lists of keypoints, where each inner list corresponds to the keypoints detected in the corresponding image.\n",
    "\n",
    "    Returns:\n",
    "        List[List[Tuple[Tuple[int, int], Tuple[int, int]]]]: List of lists of matched feature pairs, where each inner list corresponds to the matches between the corresponding pair of images.\n",
    "    \"\"\"\n",
    "    matched_features = []\n",
    "    for i in range(len(feature_list) - 1):\n",
    "        kp1, kp2 = feature_list[i], feature_list[i + 1]\n",
    "        matches = brute_force_match(kp1, kp2)\n",
    "        matched_features.append(matches)\n",
    "    return matched_features\n",
    "\n",
    "def brute_force_match(keypoints1: List[Tuple[int, int]], keypoints2: List[Tuple[int, int]]) -> List[Tuple[Tuple[int, int], Tuple[int, int]]]:\n",
    "    \"\"\"\n",
    "    Performs brute-force matching between two sets of keypoints.\n",
    "\n",
    "    Args:\n",
    "        keypoints1 (List[Tuple[int, int]]): List of keypoints for the first image.\n",
    "        keypoints2 (List[Tuple[int, int]]): List of keypoints for the second image.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[Tuple[int, int], Tuple[int, int]]]: List of matched feature pairs.\n",
    "    \"\"\"\n",
    "    matches = []\n",
    "    for kp1 in keypoints1:\n",
    "        min_dist = float('inf')\n",
    "        best_match = None\n",
    "        for kp2 in keypoints2:\n",
    "            dist = np.linalg.norm(np.array(kp1) - np.array(kp2))\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                best_match = kp2\n",
    "        if best_match is not None:\n",
    "            matches.append((kp1, best_match))\n",
    "    return matches"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
