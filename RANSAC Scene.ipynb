{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_frames_from_video\u001b[39m(video_path: \u001b[38;5;28mstr\u001b[39m, output_dir: \u001b[38;5;28mstr\u001b[39m, frame_interval: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m60\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m      9\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03m    Extracts frames from a video file at a specified interval and saves them to a directory.\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m        None\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "\n",
    "def extract_frames_from_video(video_path: str, output_dir: str, frame_interval: int = 60) -> None:\n",
    "    \"\"\"\n",
    "    Extracts frames from a video file at a specified interval and saves them to a directory.\n",
    "\n",
    "    Args:\n",
    "        video_path (str): Path to the input video file.\n",
    "        output_dir (str): Path to the output directory for saving the extracted frames.\n",
    "        frame_interval (int): Interval (in frames) at which frames are extracted. Default is 60 frames.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Open the video file\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Get the total number of frames in the video\n",
    "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Initialize the frame counter\n",
    "    frame_count = 0\n",
    "\n",
    "    # Loop through the frames and save every frame_interval-th frame\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_count % frame_interval == 0:\n",
    "            frame_path = os.path.join(output_dir, f\"frame_{frame_count}.jpg\")\n",
    "            cv2.imwrite(frame_path, frame)\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    # Release the video capture object\n",
    "    video.release()\n",
    "\n",
    "def convert_to_grayscale(images: List[np.ndarray]) -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Converts a list of RGB images to grayscale.\n",
    "\n",
    "    Args:\n",
    "        images (List[np.ndarray]): List of RGB images.\n",
    "\n",
    "    Returns:\n",
    "        List[np.ndarray]: List of grayscale images.\n",
    "    \"\"\"\n",
    "    gray_images = []\n",
    "    for image in images:\n",
    "        gray_image = np.dot(image[..., :3], [0.299, 0.587, 0.114])\n",
    "        gray_images.append(gray_image)\n",
    "    return gray_images\n",
    "\n",
    "def enhance_images(gray_images: List[np.ndarray]) -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Enhances a list of grayscale images using contrast stretching.\n",
    "\n",
    "    Args:\n",
    "        gray_images (List[np.ndarray]): List of grayscale images.\n",
    "\n",
    "    Returns:\n",
    "        List[np.ndarray]: List of enhanced grayscale images.\n",
    "    \"\"\"\n",
    "    enhanced_images = []\n",
    "    for image in gray_images:\n",
    "        min_val = np.min(image)\n",
    "        max_val = np.max(image)\n",
    "        enhanced_image = (image - min_val) / (max_val - min_val) * 255\n",
    "        enhanced_image = np.clip(enhanced_image, 0, 255).astype(np.uint8)\n",
    "        enhanced_images.append(enhanced_image)\n",
    "    return enhanced_images\n",
    "\n",
    "def detect_features(images: List[np.ndarray]) -> List[List[Tuple[int, int]]]:\n",
    "    \"\"\"\n",
    "    Detects features in a list of grayscale images using the Harris corner detector.\n",
    "\n",
    "    Args:\n",
    "        images (List[np.ndarray]): List of grayscale images.\n",
    "\n",
    "    Returns:\n",
    "        List[List[Tuple[int, int]]]: List of lists of keypoints, where each inner list corresponds to the keypoints detected in the corresponding image.\n",
    "    \"\"\"\n",
    "    feature_list = []\n",
    "    for image in images:\n",
    "        keypoints = harris_corner_detector(image)\n",
    "        feature_list.append(keypoints)\n",
    "    return feature_list\n",
    "\n",
    "def harris_corner_detector(image: np.ndarray, k: float = 0.04) -> List[Tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    Implements the Harris corner detector algorithm.\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): Grayscale image.\n",
    "        k (float): Sensitivity factor. Default is 0.04.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[int, int]]: List of keypoints (x, y) coordinates.\n",
    "    \"\"\"\n",
    "    # Compute image derivatives\n",
    "    sobelx = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobely = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "\n",
    "    # Compute Harris response matrix\n",
    "    Ixx = sobelx ** 2\n",
    "    Ixy = sobelx * sobely\n",
    "    Iyy = sobely ** 2\n",
    "\n",
    "    # Compute Harris corner response\n",
    "    harris_response = (Ixx * Iyy - Ixy ** 2) - k * ((Ixx + Iyy) ** 2)\n",
    "\n",
    "    # Find keypoints\n",
    "    keypoints = []\n",
    "    for y in range(harris_response.shape[0]):\n",
    "        for x in range(harris_response.shape[1]):\n",
    "            if harris_response[y, x] > 0.01 * harris_response.max():\n",
    "                keypoints.append((x, y))\n",
    "\n",
    "    return keypoints\n",
    "\n",
    "def match_features_across_pairs(feature_list: List[List[Tuple[int, int]]]) -> List[List[Tuple[Tuple[int, int], Tuple[int, int]]]]:\n",
    "    \"\"\"\n",
    "    Matches features across pairs of images using a simple brute-force matching approach.\n",
    "\n",
    "    Args:\n",
    "        feature_list (List[List[Tuple[int, int]]]): List of lists of keypoints, where each inner list corresponds to the keypoints detected in the corresponding image.\n",
    "\n",
    "    Returns:\n",
    "        List[List[Tuple[Tuple[int, int], Tuple[int, int]]]]: List of lists of matched feature pairs, where each inner list corresponds to the matches between the corresponding pair of images.\n",
    "    \"\"\"\n",
    "    matched_features = []\n",
    "    for i in range(len(feature_list) - 1):\n",
    "        kp1, kp2 = feature_list[i], feature_list[i + 1]\n",
    "        matches = brute_force_match(kp1, kp2)\n",
    "        matched_features.append(matches)\n",
    "    return matched_features\n",
    "\n",
    "def brute_force_match(keypoints1: List[Tuple[int, int]], keypoints2: List[Tuple[int, int]]) -> List[Tuple[Tuple[int, int], Tuple[int, int]]]:\n",
    "    \"\"\"\n",
    "    Performs brute-force matching between two sets of keypoints.\n",
    "\n",
    "    Args:\n",
    "        keypoints1 (List[Tuple[int, int]]): List of keypoints for the first image.\n",
    "        keypoints2 (List[Tuple[int, int]]): List of keypoints for the second image.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[Tuple[int, int], Tuple[int, int]]]: List of matched feature pairs.\n",
    "    \"\"\"\n",
    "    matches = []\n",
    "    for kp1 in keypoints1:\n",
    "        min_dist = float('inf')\n",
    "        best_match = None\n",
    "        for kp2 in keypoints2:\n",
    "            dist = np.linalg.norm(np.array(kp1) - np.array(kp2))\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                best_match = kp2\n",
    "        if best_match is not None:\n",
    "            matches.append((kp1, best_match))\n",
    "    return matches"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LFA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
